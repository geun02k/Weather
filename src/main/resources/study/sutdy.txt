<날씨 일기 프로젝트>
날씨를 저장하고 일기를 작성할 수 있다.


=============================== << 날씨 데이터 고르기 >> ===============================
<날씨 데이터 고르기>
1. 네이버에서 검색
	: 네이버에서 '서울 날씨' 검색 결과를 크롤링 해오는 방법
	  온도, 강수확률, 습도, 바람세기 등의 데이터 긁어올 수 있음.
	  하지만 이 데이터는 기상청에서 제공해주는 데이터를 나타내주는 것이므로
	  기존 기상청에서 제공해주는 데이터를 활용하는 게 좋을 수 있다.
2. 기상청 데이터
	: 내가 스스로 얻을 수 없는 정보들을 국가, 기업, 기관 등에서 해당 정보를 open api로 제공해준다.
	  공공데이터포털에서 기상청 api를 사용할 수 있다.
	  (공공데이터포털에서는 기상청 외의 데이터들도 준비되어있다.)
	  하지만 기상청데이터는 국내 데이터에 한정해서 제공하고 있다.
	  우리가 제공하려는 프로그램은 글로벌한 사용자를 타겟으로 할 수도 있다.
3. OpenWeatherMap Api
	: 세계적 날씨 정보를 제공하는 날씨 api
	  (해외날씨정보를 가져오고 싶어서 구글에서 free weather api로 검색한 결과로 얻은 정보.
	   사용하고자 하는 api가 있다면 구글에서 검색하면 찾을 수 있다.
	   유료 api도 있기 때문에 free로 검색.)
	: 부분적으로 무료 (1분에 60번 호출까지 무료)


<선택한 api의 사용 적합성 확인>
추후 api 종류를 변경하는 일은 어렵다.
따라서 의문사항이 생긴 것들은 api document를 통해 모두 해소를 해야한다.
- current weather data api document
  https://openweathermap.org/current

1. 제공데이터 확인하기
OpenWeatherMap Api를 사용하기로 결정한 후 해당 api를 정말 사용해도 되는지를 확인해야 한다.
OpenWeatherMap 사이트를 확인해보니 현재날씨데이터, 미래날씨예측데이터, 과거날씨데이터를 제공하고 있음을 알 수 있다.
날씨일기를 작성하기 위해서는 현재날씨와 과거날씨 정보가 필요하기에 프로젝트를 만들기위해 필요한 데이터를 제공하고있음을 알았다.
api의 세부 설명을 읽어보니 200,000 개의 도시 데이터를 제공하고 있다.
따라서 부분적 무료이고 20만개의 도시 데이터를 제공하고 있으니 사용하기 적합함을 알 수 있다.

2. api 호출방법 확인하기
api 사용 이전에 체크해야할 사항이 한가지 더 있다.
api가 사용하기 편한지도 확인이 필요하다. api는 정해진 사용 방법이 있기 때문이다. 이는 api document에 명시되어있다.
위도, 경도, api key 정보만 있으면 api에 데이터를 요청할 수 있다. (얻기에 쉬운 데이터이니 적합.)
위도와 경도가 아닌 도시 이름으로 날씨를 얻을 수는 없을까?
api document에 city를 검색하니 request by city name 이라고 도시명으로 요청을 할 수 있음을 알았다.

3. api 응답결과 확인하기
api 호출 결과가 쓸만한지 확인해야 한다.
api document에서 Fields in API response를 확인하면 알 수 있다. (response를 검색해 찾아냄.)
weather.main을 확인하니 비, 눈, 흐림 등의 데이터를 제공한다.
main에서는 체감온도, 습도, 온도 등의 데이터를 제공한다.
따라서 response에서 쓸만한 데이터가 있는 것도 확인했고 응답형식도 json 혹은 xml로 무난함을 알 수 있다.


<오픈API와 API Key>
- API 인증 (Authentication)
    : API를 호출하는 대상을 확인하는 절차
- API 인증방식
    : 방식에 따라 구현 난이도와 보완 수준이 달라진다.
    1. API Key 방식 : OpenWeatherMap api에서 사용하는 방식
    2. API Token 방식
- API Key (https://home.openweathermap.org/api_keys)
    : 특정 사용자만 알 수 있는 문자열로 구성
    : 개발자는 API 제공처에서 API Key를 발급
        -> API 호출 시 API Key를 메시지 안에 넣어 호출
        -> 서버는 메시지 안에서 API Key를 읽어들여 누가 호출한 API인지 인증
    : OpenWeatherMap API는 1분에 60번 호출까지 무료이다.
      따라서 악용되어 과금될 수 있으니 API 사용처를 인증하는 API Key는 어딘가에 업로드 하지말고 보관해야 한다.
      (git에도 업로드하면 안된다는데 그럼 어떻게 키를 불러서 호출하지?)
    ex) Request Header {
            api-key: "1231231241242144"
        }


<OpenWeatherMap API 사용방법>
- API 호출방식
    https://api.openweathermap.org/data/2.5/weather?q={city name}&appid={API key}
- seoul의 응답결과
{
    "coord": {
        "lon": 126.9778,
        "lat": 37.5683
    },
    "weather": [
        {
            "id": 800,
            "main": "Clear",
            "description": "clear sky",
            "icon": "01n"
        }
    ],
    "base": "stations",
    "main": {
        "temp": 270.91,
        "feels_like": 266.43,
        "temp_min": 270.91,
        "temp_max": 270.91,
        "pressure": 1024,
        "humidity": 69,
        "sea_level": 1024,
        "grnd_level": 1013
    },
    "visibility": 10000,
    "wind": {
        "speed": 3.6,
        "deg": 340
    },
    "clouds": {
        "all": 0
    },
    "dt": 1733574135,
    "sys": {
        "type": 1,
        "id": 8105,
        "country": "KR",
        "sunrise": 1733524421,
        "sunset": 1733559223
    },
    "timezone": 32400,
    "id": 1835848,
    "name": "Seoul",
    "cod": 200
}
- 예상 활용 정보
    - weather의 main, icon
    - main의 temp


<날씨 일기 저장 API 구현>
1. OpenWeahterMap에서 SpringBoot로 데이터 받아오기
2. 받아온 json 데이터 사용 가능하게 파싱하기
   : url을 통해 받아온 json 데이터는 20개가 넘는 다량의 데이터를 가지고 있다.
     이 20개의 정보들을 명시한 class를 만들어 데이터를 담을수도 있지만
     이는 사용하지 않을 데이터들을 담기 떄문에 비효율적이다.
     따라서 모든걸 명시한 클래스를 만들어 url 요청으로 받은 json 데이터를
     해당 클래스타입으로 변환할 수도 있지만
     이럴 때는 큰 class를 만드는 것이 아닌
     json 데이터를 파싱해와 class에 담는 방식이 더 좋아보인다.
3. SpringBoot에서 DB로 데이터 저장하기
- client, controller, service, repository 간 데이터는 DTO로 주고받음
- repository와 DB는 Entity로 데이터 주고받음


<JSON Formatter>
크롬 확장 프로그램으로 크롬에서 API 호출 시 결과값이 json인 문자열에 대해서는 JSON형태에 맞도록 한 눈에 보기 쉽게 출력해줌.




=============================== << 프로젝트 구성 >> ===============================
<프로젝트 생성하기>
스프링부트 프로젝트는 정해진 구조가 있다.
springInitializar 또는 인텔리제이나 이클립스에서 베이스프로젝트를 자동생성해주는 기능을 사용하지 않으면
스프링부트 프로젝트에서 원하는 구조대로 폴더와 파일을 일일이 생성해야 한다.


<프로젝트 메타데이터>
빌드도구
: 라이브러리들의 관리 및 프로젝트의 빌드와 실행을 수행한다.
1. maven
2. gradle - 속도도 더 빠르고 코드의 양도 적다. / maven 보다 이후에 생겨남.

스프링부트 버전
1. SNAPSHOT : 신규기능이 추가된 버전
2. M1, M2 : Milestone으로 정식버전 이전에 좀 더 정리되어진 버전
3. 괄호없음 : 안정화된 정식 배포버전

Artifact : 프로젝트명

Packaging
: 어떤 패키지 구조를 선택하느냐에 따라 프로젝트의 구조가 조금 달라진다.
빌드 실행파일 확장자도 달라진다.
1. JAR (Java Archive) : API를 제공하는 서버만 생성할 때 사용.
2. WAR (Web Application Archive) : JAR + 웹 관련 자원 / HTML,JSP같은 웹 어플리케이션을 함께 만들 때 사용

자바버전
: 자바 버전별 LTS(Long Term Support) 기간이 상이하다.
  늦게 출시되었다고 LTS가 긴 것은 아니다.
  (강의에서 8버전 사용하는데 17이 긴지, 8을 아직까지 지원하는지 확인이 필요할듯....)

Dependency
: 스프링 프로젝트에서 사용할 라이브러리 선택.
1. Lombok : 반복코드(?)인 Getter, Setter같은 코드 자동생성 (코드 간결하게 해주는 마법사)
2. Spring Web : REST API 만들 때 필수 API


<프로젝트 구동>
build.gradle 파일을 선택해 프로젝트를 오픈한다.
해당 파일만 선택해도 intellij는 스프링부트 프로젝트임을 인식해 전체프로젝트를 불러온다.


<프로젝트 구조>
폴더 앞에 .이 붙어있으면 숨김파일임.
프로젝트의 임시정보, 구동시점에만 필요한 잠깐 쓰이는 정보를 담고있다.
해당 폴더, 파일에는 직접 접근해서 작업하거나 하는 일은 거의 없다.

.gradle : gradle이 동작할 때 필요한 정보를 담고있는 폴더
.idea : 인텔리제이가 구동 시점에 필요한 정보를 담고있는 폴더
.gitignore : github에 필요한 소스코드 파일만 올리기 위해 제외정보를 담고있는 파일 (빌드한 결과물, 내 환경설정파일 제외)
			 나와 같이 협업해 프로젝트를 이끌어가는 사람은 인텔리제이가 아닌 이클립스를 사용할수도 있고
			 같은 이클립스를 사용하더라도 내 컴퓨터에 필요한 설정파일을 올릴 필요가 없다. (.idea)
			 스프링부트 프로젝트 생성시 해당 파일에 일반적으로 git에 공유하지 않는 파일들은 제외되어 있다.

gradle : 빌드한 결과물을 담고있는 폴더
src : 소스코드 위치
src/main/java : 자바 파일 위치
src/main/resources : 자바 파일을 제외한 다른 형식의 파일들 위치
build.gradle : 빌드 구성 스크립트
			 : 이전에 선택한 의존성 등과 같은 스프링 부트 프로젝트의 빌드 관련 설정 정보를 담고있는 파일
gradlew, gradlew.bat : gradle 빌드 시 사용하는 파일 (개발자가 직접 수정할 일은 없다.)


<의존성주입>
implementation : 컴파일, 테스트 모든 시점에서 사용
compileOnly : 컴파일하는 시점에만 해당 라이브러리 사용
			 lombok 라이브러리를 컴파일 시점에만 사용하는 것은
			 어노테이션들을 컴파일 과정에서 getter, setter 등을 작성한 것과 동일하게 변경해주기 때문이다.
annotationProcessor :
testImplementation : 테스트 시점에만 사용

dependency들은 mavenCentral 에서 다운받는다.
회사에서 개발할 때는 라이브러리들을 사내에서 개발하기도 하고
보안정책이나 사내 시스템에 맞는 라이브러리들을 사용하는 경우도 있다.

이럴 때는 dependencies에 해당 라이브러리를 포함하고
repositories에 사내 저장소 이름도 작성해주어야한다. (그러면 다른 저장소에서도 라이브러리를 불러올 수 있다.)





=============================== << TDD >> ===============================
<TDD, 테스트주도개발>
- Test Driven Development
- 테스트를 먼저 만들고 테스트를 통과하기 위한 코드를 짜는 것
- 테스트 코드를 먼저 작성하면 개발의 목적성이 명확해져 요구사항을 세밀하게 정리할 수 있다는 장점이 있다.

1. 테스트코드 먼저 작성하기
2. 테스트코드를 pass 하는 코드 작성하기
3. 리팩터링하기
위의 3가지를 계속 반복한다.

<Junit>
테스트코드 작성시 많이 사용되는 라이브러리

- 많이 사용되는 메서드
1. assertSame(a,b) : 두 객체 자체가 같은지 비교
2. assertEquals(a,b) : 두 객체에 정의된 equals를 통해 비교
3. assertArrayEquals(a,b) : 두 배열이 일치함을 확인
4. assertTrue(a) : 참인지 확인
5. assertNotNull(a) : null이 아닌지 확인





=============================== << DB에서 작업하기 >> ===============================
<Persistence Framework - SQL Mapper / ORM>
- Persistencd (영속성)
  : 데이터를 생성했던 프로그램이 종료되더라도 데이터가 휘발되지 않는 것.

- Persistence Framework
	: 데이터를 생성했던 프로그램이 종료되더라도 데이터가 휘발되지 않도록 도와주는 프레임워크
	: DB와 연동되는 시스템을 빠르게 개발(Spring, DB연결)
	  Persistence Framework가 없다면 SpringBoot와 DB와 연결하는 부분을 직접 관리해야 한다.
	  db와의 연결여부, query의 이상여부에 따라 if-else문으로 분기처리해야한다.
	  또한 db와 연결이 되어있는지 계속 확인해야 하고
	  db와 연결여부에 따라 if-else 분기처리해야한다.
	  그리고 db 사용이 끝나면 연결을 직접 끊어주어야한다.
	: 안정적인 구동을 보장해주는 프레임워크
	- 재사용, 유지보수에 용이
	- 직관적인 코드

1. SQL Mapper
	- SQL을 개발자가 직접 작성
	- 매핑 : 쿼리수행결과 <-> 객체
	- 단점
		- DB종류 변경시 쿼리 수정 필요
		- 비슷한 쿼리 반복적 작성 필요 ex) select * from 테이블명 -> 테이블마다 조회쿼리 작성 반복

2. ORM (Object Relation Mapping)
	- Object와 DB 테이블 맵핑
	- java 메서드 사용 -> 자동 SQL 생성.
	- 매핑 : DB테이블 <-> 객체
	- 단점
		- 복잡한 쿼리를 자바 메서드 만으로 해결하는 것이 불편.


<JPA / JDBC>
1. JPA (Java Persistence API)
	- ORM의 한 종류로 Java에서 사용. (자바 ORM 기술의 표준 명세)
	- 객체와 테이블의 연결된 정보만 알려주면 쿼리를 대신 짜줌.

	Application			O/R Mapper			JDBC interface		JDBC Implementations	Persistence Layer
	Modules
	---------------------------------------------------------------------------------------------------------
	service
	->repository---------> Spring Data JPA
						   -> JPA
	->repository Impl----> Hibernate -------> JDBC Basic APIs ---> JDBC Driver			Database
									 -------> DataSource -------->
											  (Configuration for connection)

2. JDBC (Java Database Connectivity)
	: 자바에서 DB를 사용할 수 있도록 제공해주는 최소한의 API. (단순히 DB와 Java 연결)
	- SQL Mapper의 한 종류로 Java에서 사용.

	Application		JDBC interface		JDBC Implementations	Persistence Layer
	-----------------------------------------------------------------------------
	DTO				Spring JDBC			JDBC Driver				Database
					(ex> JdbcTemplate)

					DataSource
					(Configuration for connection)


<JDBC 사용하기>
1. build.gradle에 jdbc, mysql 관련 라이브러리 추가
   - implementation 'org.springframework.boot:spring-boot-starter-jdbc'
   - runtimeOnly 'com.mysql:mysql-connector-j'

2. application.properties 파일에 DB 접속정보 저장
   - 미설정 시 서버 실행 시 아래의 오류 발생
     Failed to configure a DataSource:
     'url' attribute is not specified and no embedded datasource could be configured.
   - 설정정보
     spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
     # ?serverTimezone=UTC&characterEncoding=UTF-8 설정은 optional한 부분
     # 데이터베이스의 시간대와 인코딩방식 설정
     spring.datasource.url=jdbc:mysql://localhost:3306/project?serverTimezone=UTC&characterEncoding=UTF-8
     spring.datasource.username=root
     spring.datasource.password=zerobase

3. MySQL에 데이터베이스, 테이블생성
   - Project 데이터베이스 생성
   - Memo 테이블 생성

4. 테이블과 매칭되는 자바 클래스 생성
   - Memo 테이블과 매칭되는 Memo.java 클래스(도메인) 생성

5. JdbcMemoRepository 생성
    - JDBC를 이용해 MySQL과 Spring 사이에 데이터 전송이 가능하도록 하기위해 저장소 생성.

6. 테스트코드 작성


<JPA 사용하기>
1. build.gradle 파일에 jpa 관련 라이브러리 추가
   - implementation 'org.springframework.boot:starter-data-jpa'

2. application.properties 파일에 DB 접속정보 저장
   - jdbc의 기존 접속정보를 유지하고 아래의 두 설정 추가
   - spring.jpa.show-sql=true
     : 쿼리 출력 여부 설정 (JPA는 쿼리를 자동생성해주기 때문에 출력해 확인 필요시 true)
   - spring.jpa.database=mysql
     : 어떤 데이터베이스를 쓰는지 작성

3. Memo 클래스에 @Entity 어노테이션을 사용해 Entity화 하기
   - JPA는 스프링부트의 클래스와 DB의 테이블을 매핑하는 것이다.
     이 때 테이블의 스프링부트의 여러 클래스들을 하나의 DB 테이블에 매핑시키는 경우도 있을 수 있다. (하나의 테이블에 여러 Entity 매핑가능)
     이런 경우에는 각각의 클래스들을 Entity로 지정해 테이블과 연결할 수 있다.
     따라서 클래스의 @Entity 어노테이션을 이용해 연결된 테이블과 사용할 값들을 명시해주게 된다.

     -> @Entity
     name 속성을 설정해주지 않고 @Entity만 사용하게 되면
     클래스명과 동일한 이름의 테이블과 매핑된다.
     -> @Entity(name="Memo")
        : Memo 테이블에 매핑된 Entity
        : name 속성에 클래스과 매핑할 테이블명을 작성한다.

     예를들면 어떤 Entity는 Memo 테이블의 id값만 사용하고 싶을 수 있다.
     그런 경우 id값만 가지는 Entity를 생성할 수 있다.
     그리고 id, text 정보를 모두 가지는 Entity를 또 생성할 수 있다.
     이렇게 활용 방안에 따라서 하나의 테이블에 대해 여러 Entity를 생성할 수도 있다.

     - @Id : 테이블의 pk 필드에 해당 어노테이션 필수 추가
     - @GeneratedValue : 값 자동증가 필드에 사용
                         아래는 strategy 속성의 값
                        - GenerationType.AUTO : 자동증가
                        - GenerationType.IDENTITY : 키 생성을 DB에 위임(스프링부트는 키생성x)
                        - GenerationType.SEQUENCE : 데이터베이스 Object를 만들어서 키 생성해줌
                        - GenerationType.TABLE : 키생성을 위한 테이블을 생성해 제공

4. Memo 클래스에 @Table 붙이기 (생략가능)
   - @Table(name="Memo")
     : @Entity에서 name 속성을 이용해 매핑 테이블을 지정하지 않고
       @Table 어노테이션을 추가로 이용해 매핑 테이블을 지정할 수도 있다.

5. JpaMemoRepository 구현
   - JpaRepository 클래스를 상속받아 해당 클래스를 생성하기만해도
     여태까지 JdbcMemoRepository에 작성했던 메서드들 호출이 가능하다.
     따라서 JdbcMemoRepository와 JpaMemoRepository의 코드 양의 차이가 확연히 들어난다.

   - JpaRepository
     JPA는 ORM의 자바 표준 명세이다.
     따라서 자바에서 ORM 개념을 활용할 때 쓸 메서드들은 JpaRepository에 이미 모두 정의가 되어있다.
     개발자는 그저 메서드를 가져와 사용하기만하면 된다.

   - JpaRepository<클래스, pk의타입>
     : 어떤 클래스를 가져와 연결할건지, 테이블의 pk 타입은 무엇인지 명시적으로 작성이 필요하다.

6. 테스트코드 작성
   - JpaMemoRepositoryTest.java inertMemoTest() 에서 아래와 같이 객체 생성 시 select문만 2번 출력하고 오류발생
        - 객체생성방법 : Memo newMemo = new Memo(1, "testText");
        - 오류 : Row was updated or deleted by another transaction (or unsaved-value mapping was incorrect):
                    [zerobase.weather.domain.Memo#1]
                org.springframework.orm.ObjectOptimisticLockingFailureException:
                    Row was updated or deleted by another transaction (or unsaved-value mapping was incorrect):
                    [zerobase.weather.domain.Memo#1]
        - 해결하는데 참고된 블로그 : https://programmer-chocho.tistory.com/80





=============================== << MVC패턴 >> ===============================
<Controller>
- @RestController : 기본 @Controller 어노테이션을 사용할 때와 달리
                    http 응답을 보낼 때 상태코드를
                    controller에서 지정해서 내려보낼 수 있게 해준다.
- @RequestParam : http 요청 url ? 뒤에 오는 데이터를 얻을 때 사용 (파라미터 형식)
                  ex) http://localhost/craete/diary?date=20241201
- @RequestBody : http 요청의 request body 부분의 정보 얻을 때 사용
- @DateTimeFormat : 데이터타입 포맷설정
                    날짜는 여러 형식으로 저장될 수 있기 때문에
                    받을 날짜 데이터의 포맷을 하나로 정의할 떄 사용
- 테스트
    1. 브라우저에서 요청 url을 작성해 테스트하는 방법
       해당 방식은 Get방식의 요청으로 인식한다.
       따라서 POST 같은 요청을 보내기에는 적합하지 않은 방법이다.
       브라우저는 요청으로 받아온 웹사이트 정보를 빨리빨리 서빙을 해줘야한다.
       따라서 브라우저는 기본으로 캐싱을 한다.
       그렇기에 api 요청 테스트를 할때는 현재 요청에 대한 결과값을 정확히 보고싶은데
       캐싱된 데이터의 영향을 받아서 예상과 다른 결과값이 나올 수 있기 때문에 적합하지 않다.
    2. Post Man 사용
       - 요청 url 작성란에 아래와 같이 host라는 변수를 url에 작성 시
         환경마다 host url을 다르게 지정해두면
         환경만 변경해 같은 url로 더 간편하게 테스트 가능
         http://{(host)}/create/diary?date=2022-05-12


<Service>
- @Value : import org.springframework.beans.factory.annotation.Value; (lombok의 @value 아님 주의)
           .properties 파일에 정의된(?) key에 대한 value값 가져오기

           - in DiaryService
             @Value 어노테이션을 사용해 apikey값을 가져오는 이유
             application.properties는
             지금 로컬환경이라는 단 하나의 환경에 대한 설정정보를 담고있지만
             실무 개발 시에는 로컬, 개발테스트, 운영환경과 같이 여러 환경이 존재한다.
             이 다양한 환경들은 같은 DB를 바라보지 않는다. 따라서 환경별로 다른 DB를 지정하게 된다.
             그런 환경 분리는 resource 폴더 아래의 properties 파일에서 properties를 환경마다 지정해주고
             코드상에서는 환경과 무관하게 아래와 같이 키값만 가지고 value를 불러올 수 있다.

<Repository>
- save() : save()는 저장하는 메서드가 아니다.
           존재하지 않는 id에 대해서는 신규 insert를 수행하게 되지만
           동일 id에 대해 save() 메서들를 호출하게 되면
           해당 id에 데이터를 덮어쓰는 update를 수행하게 된다.
- delete() : 해당 메서드 호출 시 아래의 에러 발생.
             jakarta.persistence.TransactionRequiredException:
                No EntityManager with actual transaction available for current thread
                    - cannot reliably process 'remove' call
             - repository에서 해당 메서드 위에 @Transactional 어노테이션을 사용해 정상적으로 delete() 메서드가 실행될 수 있도록 한다.
               해당 어노테이션이 필요한 이유는, 내가 작성한 deleteAllByDate() 메서드는 단 한건의 delete문만 실행하는 것이 아닌
               delete문을 실행해야할 수 있기 때문이다. (아래의 <<트랜잭션>> 부분이 도움이 될 것.)
             - 해당 어노테이션 작성 시 2개의 import문이 뜨는데 아래의 클래스를 import해준다.
               jakarta보다 더 많은 부가기능을 제공하기 때문이다. (사실상 부가기능 사용하지 않아 어떤 것을 쓰든 상관없음.)
               import org.springframework.transaction.annotation.Transactional;
             - 참고 블로그 (두 @Transactional의 차이)
               : https://velog.io/@chiyongs/Transactional-%EC%96%B4%EB%96%A4-%EA%B1%B8-%EC%82%AC%EC%9A%A9%ED%95%B4%EC%95%BC-%ED%95%A0%EA%B9%8C

<Domain>





=============================== << 트랜잭션(Transaction) >> ===============================
< 트랜잭션 >
  : 데이터베이스의 상태를 변화(쿼리를 이용해 DB를 수정,삭제,삽입하는 것)시키기 위해 수행하는 작업 단위.
  : 주로 DB에 문제 발생 시 rollback 하기위해 사용된다.


< 트랜잭션 연산 (트랜잭션의 원자성 만족) >
1. commit : 트랜잭션 전체가 성공적으로 완료되었을 때 DB에 수정사항 반영.
2. rollback : 트랜잭션 수행 중 문제 발생 시 DB에 수행했던 작업들의 수정사항 반영 취소.

ex) 트랜잭션 = 오늘일기 작성하기
    작업단위 1. 오늘 날씨 일기 데이터 가져오기
            2. 일기를 DB에 저장하기
: 날씨 데이터가 당연히 있을 것이라는 가정 하에 DB를 구성했는데
  날씨 데이터를 가져오지 못했다면 불완전한 일기 데이터가 저장될 것이다.
  따라서 날씨 데이터를 가져오지 못했거나 일기를 DB에 저장하는 과정에서 문제가 발생하면
  Transaction 자체를 rollback 시키는 작업이 필요하다.
  이를 위해 @Transaction 어노테이션을 사용해야 한다.


< 트랜잭션 특성 >
1. 원자성(Atomicity)
   : 변경사항이 DB에 모두 반영되거나 모두 반영되지 않아야 한다.

2. 일관성(Consistency)
   : 트랜잭션의 작업처리 결과는 항상 일관적이어야 한다.
     (동일 작업에 대해 결과는 항상 같아야 한다.)
   - 여러 트랜잭션이 특정 값을 경쟁하면 생기는 문제1
     ex) 트랜잭션A : Diary 테이블의 3번째 row 조회 처음과 마지막에서 각각 1번씩 2번 수행
         트랜잭션B : Diary 테이블의 3번째 row 수정 후 커밋이 트랜잭션A 도중 발생
         2. Non-Repeatable Read
           : 트랜잭션A가 처음 조회 쿼리를 날린 후 추후 2번째 조회 쿼리를 날리기 전에
             트랜잭션B 작업이 수행되어 트랜잭션A의 두 조회 결과가 다른 값을 가지게 된다.
             이는 트랜잭션A에 대해 일관성을 해치는 행위가 된다.
   - 여러 트랜잭션 특정 범위 내에서 경쟁하면 생기는 문제3
     ex) 트랜잭션A : Diary 테이블의 0~4번째 row 조회 처음과 마지막에서 각각 1번씩 2번 수행
         트랜잭션B : Diary 테이블의 3번째 row 수정 후 커밋이 트랜잭션A 도중 발생
         3. Phantom Read

3. 독립성(Isolation)
   : 하나의 트랜잭션 수행 중 다른 트랜잭션이 끼어들 수 없다.
   - 여러 트랜잭션이 경쟁하면 생기는 문제2
     ex) 트랜잭션A : Diary 테이블의 3번째 row 수정중
         트랜잭션B : Diary 테이블의 3번째 row 조회하려 함
         1. Dirty Read 문제 발생
            : 트랜잭션A가 해당 row의 특정 컬럼의 값을 기존1에서 2로 변경했다.
              이 때 트랜잭션B가 도중에 데이터를 읽어가고
              추후 트랜잭션A에 문제가 발생해 rollback되어 컬럼의 값이 다시 1로 변경되었다.
              이렇게되면 트랜잭션B는 존재하지 않는 2라는 값을 읽어간 것이 된다.

4. 지속성(Durability)
   : 트랜잭션이 성공적으로 완료되었다면 변화된 상태가 쭉 지속되어야 한다.
     (영구적으로 반영되어야 한다.)


< Spring에서 Transaction 지원하기 (스프링 트랜잭션 세부설정) >
  : 스프링에서는 트랜잭션을 지원하는 여러 방식이 존재한다.
- @Transactional
  : 가장 간단하고 널리 쓰이는 방식. (선언적 트랜잭션)
  : 클래스, 메서드 위에 해당 어노테이션 추가 가능.
  : 해당 어노테이션을 통해 트랜잭션의 단위를 지정해준다. (하나의 함수를 트랜잭션으로 만들어줄 수 있다.)
  : 해당 어노테이션이 추가되면 추가된 클래스나 메서드에 트랜잭션 기능이 적용된 프록시 객체를 생성된다.
    프록시 객체는 @Transactional이 포함된 메서드가 호출된 경우 PlatformTransaction Manager를 사용해
    트랜잭션을 시작하고, 트랜잭션 안의 작업단위들을 관리해준다.
    즉 PlatformTransaction Manager가 트랜잭션 안의 작업 단위들이 성공했는지 예외가 존재했는지를 판단해
    commit 또는 rollback 작업을 수행한다.
  - @Transactional 어노테이션을 테스트코드에서 사용 시
    : 테스트코드로 인해 데이터베이스의 정보가 변경되지 않도록 하기 위한 어노테이션.
    : 테스트코드를 실행 후 DB를 원상태로 복구한다. (테스트코드에서 예외적임.)

< Spring Transaction 세부설정 >
: 트랜잭션들끼리 경쟁했을 떄 발생 가능한 문제점들이 생기지 않도록
  한 트랜잭션의 수행의 종료까지 기다렸다가 종료 후 다음 트랜잭션을 수행하는 것은
  수행시간이 아주 길어지게 될 것이다.
  이는 응답시간이 아주 느려질 것이다.
  따라서 트랜잭션의 수행시간과 요청에 대한 응답시간을 합리적으로 만들어야 한다.
  그렇기 때문에 Spring Transaction에서 지원하는 아래의 추가 설정들을 통해 해결할 수 있다.

  하지만 실무에서 격리수준을 직접 하나하나 다 지정하는 경우는 잘 없다.
  보통 격리수준은 DEFAULT로 지정을 하고 계좌정보나 돈에 관련된 한치의 오차도 허용하기 힘든 경우만
  해당 트랜잭션에 격리수준을 REPEATABLE_READ 또는 SERIALIZABLE을 사용한다.

1. Isolation (격리수준)
   : 트랜잭션에서 일관성 없는 데이터를 허용하는 수준
   ex) @Transactional(isolation=Isolation.DEFAULT)
   - DEFAULT : 각 사용하는 DB마다 Isolation 수준들의 default값이 있다.
               따라서 DB의 Isolation default값을 따른다.
   - READ_UNCOMMITTED -> Dirty Read 발생가능 (0레벨)
                      : 트랜잭션A가 실행 중이더라도 트랜잭션B의 읽기를 허용한다.
                      : 조회 시 값이 잠깐 잘못 나오는 것 정도는 괜찮은 경우 사용.
                        값의 일관성보다 빠른 응답시간이 더 중요한 경우 사용.
   - READ_COMMITTED -> Dirty Read 방지 (1레벨)
                    : 트랜잭션A에서 commit된 확정 데이터만 트랜잭션B가 읽기 허용.
   - REPEATABLE_READ -> Non-Repeatable Read 방지 (2레벨)
                    : 트랜잭션A가 완전히 완료될 때까지 select 중인 부분에 대해 타 트랜잭셔넹서
                      수정,추가,조회가 불가하도록 sharedLock을 건다.
                      해당 테이블 영역에 대해 타 트랜잭션은 조회조차 불가하도록 한다.
   - SERIALIZABLE -> Phantom Read 방지 (3레벨)
                  : 데이터의 일관성과 동시성을 위해 트랜잭션이 완료될 때 까지 사용하고 있는 모든 데이터에 sharedLock을 건다.
                    다른 사용자는 해당 영역에 대한 데이터를 수정,입력,조회 불가하도록 한다.
                  : 트랜잭션이 절대 어떠한 오류도 발생하면 안되는 경우 사용.
                    응답시간은 포기하고 트랜잭션의 규정을 절대적으로 지켜 수행.
                    따라서 성능저하는 어쩔 수 없다.

2. Propagation (전파수준)
   : 트랜잭션 동작 도중 다른 트랜잭션을 호출하는 상황에서
     트랜잭션을 시작하거나 기존 트랜잭션에 참여하는 방법에 대해 결정하는 속성값.
     (A메서드와 B메서드 모두에 @Transactional 어노테이션이 사용되었을 때 A에서 B를 호출하는 경우
      A트랜잭션에 B를 포함할 것인지, A와 B를 두개의 별도의 트랜잭션으로 여길 것인지 결정.)
   - REQUIRED : default 속성.
              : 트랜잭션A는 부모 트랜잭션, 트랜잭션B는 자식 트랜잭션으로 여긴다.
                따라서 부모 트랜잭션에 자식 트랜잭션을 포함시킨다.
                단, 부모 트랜잭션이 없이 메서드B만 단독 호출하는 경우 트랜잭션B는 단독 트랜잭션을 생성한다.
   - SUPPORTS : 이미 시작된 트랜잭션이 있으면 참여하고 없으면 트랜잭션 없이 진행한다.
              : 부모 트랜잭션이 있으면 부모에 포함되고, 단독 호출되는 경우에는 트랜잭션을 생성하지 않고 수행한다.
   - REQUIRES_NEW : 부모 트랜잭션이 존재하더라도 자식만의 단독 트랜잭션을 생성한다.
   - NESTED : 이미 시작된 트랜잭션이 있는 경우에 중첩 트랜잭션을 시작한다.
              이미 실행되고 있는 트랜잭션 안에 또 하나의 트랜잭션을 만드는 것이다.
              부모안에서 생성된 중첩된 트랜잭션은 부모 트랜잭션이 commit 되는지 rollback 되는지에 영향을 받지만
              중첩된 트랜잭션의 commit, rollback 여부는 부모 트랜잭션에 영향을 주지 않는다.
              (부모에 문제 발생 시 자식 트랜잭션도 함께 rollback,
               부모는 문제가 없는데 자식에 문제 발생 시 자식은 rollback하고 부모 트랜잭션은 commit)
            ex) 날씨 일기 작성 관련해서 로그를 DB에 저장하는 상황에서 사용 가능.
                1. 로그 저장이 실패한다고 해서 일기 작성까지 rollback되면 안됨.
                2. 일기 작성이 실패한다면 로그 작성까지 rollback되어야 함.
   ...

3. ReadOnly 속성
   : 트랜잭션을 읽기 전용 속성으로 지정.
   - 성능 최적화를 위해 사용가능
     : readOnly=true 시 트랜잭션의 동작 성능이 더 빨라진다.
       클래스에 트랜잭션이 여러개 존재할 때 클래스에 readOnly=true로 설정한다면
       수정이 필요한 트랜잭션에만 readOnly=false 작업을 해주고 그 외 readOnly=true를 붙여주면
       해당 로직의 성능향상 가능.
       (조회만 하는 경우는 readOnly=true를 해두는 게 정말 좋다.)
   - 특정 트랜잭션 작업 안에서 읽기 이외의 작업이 일어나는 것을 의도적으로 방지하기 위해서도 사용가능.
     : 해당 어노테이션을 사용하는 경우 읽기 외 동작 수행 시 예외발생
   : default값은 false.
   ex) @Transactional(readOnly=true)

4. 트랜잭션 롤백 예외
   : 특정 예외가 발생했을 때 트랜잭션 롤백여부 설정.
   - default값은 스프링에서 트랜잭션 도중 RuntimeException, Error 발생시 rollback.
    ex) @Transactional(rollbackFor=Exception.class) // 모든 예외가 발생했을 때 rollback
                                                    // 만약 Exception이 아닌 다른 특정 예외를 설정한다면
                                                       해당 예외에 대해서만 롤백수행.
        @Transactional(noRollbackFor=Exception.class)

5. timeout 속성
   : 일정 시간 내에 트랜잭션을 끝내지 못하면 rollback.
     (격리수준이 높은 트랜잭션에 대해 DB또는 스프링에서 문제가 발생하여 오랜 시간동안 트랜잭션이 종료되지 않을 경우 함께 사용하면 좋음.)
   ex) @Transactional(timeout=10)



< Spring Transaction 적용하기 >
- @EnableTransactionManagement : 해당 클래스 내에서 트랜잭션이 동작할 수 있도록 허용한다.
                                 따라서 모든 @Transactional 어노테이션을 사용할 곳에 추가하는 것이 아니라
                                 스프링의 시작점인 WeatherApplication.java 클래스에 적용하는 것이 가장 좋다.
                                 (= 해당 프로젝트 내에서 트랜잭션 동작을 허용한다.)
- @Transactional 외에도 @EnableTransactionManagement 어노테이션을 함께 사용해야 프로젝트 내에서 트랜잭션들이 정상적으로 동작한다.
- 메소드에 일일이 @Transactional 어노테이션을 적용하지 않고 class에 일괄적으로 적용 가능하다.
- class에 @Transactional 어노테이션을 적용했는데 내부의 메서드에 또 @Transactional 어노테이션을 적용한 경우에
  속성값은 내부 메서드에 적용한 속성값을 따른다.
- 일반적으로 service 로직에 해당 어노테이션을 많이 사용한다.





=============================== << 캐싱 & 스케줄링 >> ===============================
< 캐싱 >
  : 데이터 등을 미리 복사해 저장해두는 것.
  - 요청을 빠르게 처리 가능.
  - 클라이언트 입장에서는 요청에 대한 응답이 빨라서 좋고
    서버 입장에서는 처리해야할 양이 줄어 서버에 부하가 줄게 됨.
  - 요청한 것에 대한 응답이 변하지 않을 때만 사용 가능.
    ex) 이전 날짜에 대한 정보는 변하지 않으므로 캐싱 가능.
        하지만 미래 날짜에 대한 날씨 예측값은 변동 가능하므로 캐싱 불가.
  - OpenWeatherMap API 처럼 분당 호출 횟수에 대해 유료인 경우는,
    호출 횟수를 줄이는 효과로 인해 사용료 절감가능.


< 캐싱방법 >
  1. 웹 브라우저에서 캐싱
  2. 서버에서 캐싱 (DB에 데이터 저장)


< 현재 프로젝트에 캐싱 적용하기 >
  : 하루에 한 번 날씨 데이터를 저장한다.

  - 현재 프로젝트에서 캐싱적용 시 이점
    : createDiary()에서 매번 다이어리를 쓸 때 마다 api를 호출해 날씨정보를 가져와 파싱하는 불필요한 과정 생략.
      매일 api를 호출해 날씨 데이터를 가져와 저장해두었기 때문에 과거 날씨 데이터를 api를 통해 조회하는 것도 유료인데
      해당 건도 무료로 서빙가능하다.

  1. 매일 새벽 1시에 외부 api에서 전일 날씨 데이터 얻어오기.
     - WeatherApplication.java 에 @EnableScheduling 어노테이션 추가
       : 해당 프로젝트에서 Scheduling 기능을 사용할 수 있게 활성화.
     - @Scheduled 어노테이션 사용.
     - cron 표현식 : 특정시간마다 실행할 때 사용

     ex) @Scheduled(cron="0 0 1 * * *") // 매일 새벽 1시에 실행
     ex2) 0 0 * * * * // 매 시각
     ex3) */10 * * * * * // 10초 마다
     ex4) 0 0 8-10 * * * // 매일 8,9,10시

     - cron 옵션
       - second (0 ~ 59)
       - minute (0 ~ 59)
       - hour (0 ~ 23)
       - day of the month (1 ~ 31)
       - month (1 ~ 12 or JAN ~ DEC)
       - day of the week (0 ~ 7 or MON ~ SUN)

  2. DB에 해당 데이터 저장.

  3. 전일 날씨 데이터가 필요할 때는 외부 api를 호출하지 않고 DB에 접근해 데이터 얻어오기.





=============================== << 로그 >> ===============================
< 로그 사용 이유 >
  1. 서비스 동작 상태 파악
  2. 장애 파악


< 로그 작성 법 >
  1. System.out.println()
     : 로그를 파일에 쌓아주거나, 오래된 로그를 자동 제거해주는 기능x (콘솔에서만 확인가능)
     : 콘솔에 출력물이 쌓이게 되면 어떤 로그가 중요하고 문제가 되는 로그인지 파악에 어려움.
  2. Logging library 사용
     - log4j(로그포제이, 로그포자바) -> log4j2
       : 스프링부트, 자바에서 사용하는 로깅 라이브러리
       : log4j2는 logback의 기능을 많이 포함함.
     - logback : log4j보다 이후 생겨나 기능 많음.


< 로그레벨 >
  : 라이브러리마다 상이함.(아래는 logback의 로그레벨)
  : 보통 Error, Warn, Info 정보의 레벨만 로그 파일에 데이터를 쌓게끔 설정한다.

  1. Error 에러 : 즉시조치필요 (DB와 연결불가)
  2. Warn 주의 : 로직상 유효성 확인시 사용, 예상가능한 문제였는데 계속 발생여부를 확인할 떄 사용.
              : 당장 서비스를 하는데는 상관없지만 꽤 높은 수준의 문제로 파악하고 봐야하는 로그 작성.
  3. Info 정보 : 서비스를 운영하는데 있어서 참고할만한 중요작업 종료 시 사용.
                (새벽 1시에 발생한 api 호출 결과를 DB에 잘 저장했음 같은 정보 출력)
  4. Debug 디버그용 : 개발 단계에서 많이 사용
  5. Trace 출력 : 개발 단계에서 많이 사용


< logback 라이브러리 >
: 해당 라이브러리는 기본적으로 스프링부트에 내장되어있다. (build.gradle에 의존성추가 필요없음)


< logback 설정파일 (logback-spring.xml) >
- 각각의 Appender를 만들고 Appender가 어떤 로그를 담고 어떻게 저장할 것인지 각각 설정가능.
- application.properties에 로그 환경설정파일을 지정해주고 서버 실행시
  logs폴더  error_file.log, log_file.log 파일 자동생성
  : logging.config=classpath:logback-spring.xml
- 참고블로그
  : https://lovethefeel.tistory.com/89

- RollingFileAppender : 몇일동안의 로그를 저장할 것인지 설정하고 가장 이전에 생성된 로그부터 지운다.
                        예를 들어 10일간의 로그를 저장하기로 설정했다면
                        11일이 되었을 때 1일자의 로그를 지우고 11일자의 새로운 로그파일을 생성한다. (10개의 파일만 저장)
- Console Appender : 콘솔창에 출력할 로그들 설정
- File Appender : 파일에 저장할 로그들 설정
- Error Appender : Error 로그 수준은 꼭 확인해야하므로 File Appender와 따로 분리하도록한다.
                   해당 로그 파일이 비어있어야 프로젝트에 문제가 없는 상태임을 알 수 있다.

<?xml version="1.0" encoding="UTF-8" ?>
<configuration>
    <!-- 변수값 설정 -->
    <property name="LOGS_PATH" value="./logs"/> // 로그가 쌓일 경로를 /logs로 지정
    <property name="LOGS_LEVEL" value="INFO"/> // INFO 이상의 로그레벨만 파일에 저장

    <!-- Console Appender -->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <!-- 출력 패턴 설정 -->
        <layout class="ch.qos.logback.classic.PatternLayout">
            <pattern>%d{HH:mm} %-5level %logger{36} - %msg%n</pattern>
        </layout>
    </appender>

    <!-- File Appender -->
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 파일명과 경로설정 -->
        <file>${LOGS_PATH}/log_file.log</file>
        <!-- 출력 패턴 설정 -->
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>[%d{yyyy-MM-dd HH:mm:ss}:%-3relative][%thread] %-5level %logger{35} - %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- Rolling 정책 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- .gz, .zip 등을 넣으면 자동 일자별 로그파일 압축 -->
            <fileNamePattern>${LOGS_PATH}/%d{yyyy-MM-dd}_%i.log</fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <!-- 파일당 최고 용량 -->
                <maxFileSize>10MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <!-- 일자별 로그파일 최대 보관주기(~일), 해당 설정일 이상된 파일은 자동으로 제거 -->
            <maxHistory>60</maxHistory>
        </rollingPolicy>
    </appender>

    <!-- Error Appender -->
    <appender name="Error" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 파일명과 경로 설정 -->
        <file>${LOGS_PATH}/error_file.log</file>
        <!-- 출력 패턴 설정 -->
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>[%d{yyyy-MM-dd HH:mm:ss}:%-3relative][%thread] %-5level %logger{35} - %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- Rolling 정책 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- .gz, .zip 등을 넣으면 자동 일자별 로그파일 압축 -->
            <fileNamePattern>${LOGS_PATH}/%d{yyyy-MM-dd}_error.log</fileNamePattern>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <!-- Threshold Filter 이용해 error이상의 로그만 걸러지도록 함. -->
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>ERROR</level>
        </filter>
    </appender>

    <root level="${LOGS_LEVEL}">
        <appender-ref ref="STDOUT"/>
        <appender-ref ref="FILE"/>
    </root>
</configuration>





=============================== << 예외처리 >> ===============================
< Spring의 기본적인 예외처리 >
1. white label page
   : 잘못된 페이지(url) 요청 시 스프링에서 기본적으로 제공하는 white label page(에러페이지) 출력

2. DiaryController에서 createDiary() 메서드의 아래의 파라미터는 타입을 지정해주었다
   @RequestParam @DateTimeFormat(iso = DateTimeFormat.ISO.DATE) LocalDate date
   만약 날짜일자가 아닌 다른 값이 인자로 전달될 경우 스프링에서 기본적으로 400 Bad Request 에러를 반환하게된다.
   이는 스프링 컨트롤러단에서 알아서 예외처리를 수행해 준 결과이다.


< 활용할 수 있는 예외처리 - 코드의 부분부분 예외처리 >
  : 해당 기능(?)을 이용해서는 개발자가 예상가능한 예외만 처리가 가능하다.
    그 많은 예상가능한 예외들을 일일이 try-catch문을 이용해 작성하기도 어렵다.
    이렇게 되면 코드의 대부분이 예외처리코드로 이루어지고 코드의 가독성도 떨어지게 될 것이다.
    또한 예측 불가능한 곳에서 더 많은 에러가 발생한다.
    따라서 try-catch, custom Exception을 이용해 모든 예외처리를 한다는 것은 불가능하다.

    1. try-catch문으로 처리 : java에서 지원하는 예외처리 형태.
    2. custom Exception 만들어서 처리


< 활용할 수 있는 예외처리 - 코드의 전반적인(전역적인) 부분에 대한 예외처리 >
: 서비스 전역에서 발생하는 예외처리를 수행할 수 있는 방법.
- Exception Handler
 : @Controller, @RestController의 예외를 하나의 메서드에서 처리해주는 기능.

1. @ExceptionHander()
   : 하나의 컨트롤러에 대해서만 예외처리 수행.
   : Controller.java 에서 @ExceptionHander() 어노테이션을 이용해 예외처리 할 메서드를 생성해 이를 수행하면
     해당 Controller 내에서만 에외를 처리한다. (프로젝트 전체에 대한 예외처리x)
     - @ExceptionHander() : 모든 예외에 대해 처리
     - @ExceptionHander(InvalidException.class) : 특정 예외 케이스에 대해 예외 처리.

2. @ControllerAdvice
   : 모든 Controller 단을 대상으로 예외처리 수행.
   : 일관성있는 에외처리를 위해서 @ControllerAdvice 어노테이션을 추가한 핸들러 클래스를 이용한다.
     해당 핸들러 클래스에 예외처리 메서드들을 추가해 관리한다.
     (Controller마다 동일 예외에 대해서 예외처리 메서드를 반복해 생성하지 않고 한번에 해결가능)
